{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["* Refrences for code of Siamese network: https://keras.io/examples/vision/siamese_network/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import time\n","import random\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras.applications.inception_v3 import preprocess_input\n","from tensorflow.keras import backend, layers, metrics\n","\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import Xception\n","from tensorflow.keras.models import Model, Sequential\n","\n","from tensorflow.keras.utils import plot_model\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","tf.__version__, np.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Setting random seeds to enable consistency while testing.\n","random.seed(5)\n","np.random.seed(5)\n","tf.random.set_seed(5)\n","\n","ROOT = \"/kaggle/input/face-recognition-dataset/Extracted Faces/Extracted Faces\"\n","# function to read an image and resize it\n","def read_image(index):\n","    path = os.path.join(ROOT, index[0], index[1])\n","    image = cv2.imread(path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    image=cv2.resize(image, (128,128), interpolation = cv2.INTER_AREA)\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# splitting the data so that we can have a subset of people that have not been seen by the model\n","def split_dataset(directory, split=0.9):\n","    folders = os.listdir(directory)\n","    num_train = int(len(folders)*split)\n","    \n","    random.shuffle(folders)\n","    \n","    train_list, test_list = {}, {}\n","    \n","    # Creating Train-list\n","    for folder in folders[:num_train]:\n","        num_files = len(os.listdir(os.path.join(directory, folder)))\n","        train_list[folder] = num_files\n","    \n","    # Creating Test-list\n","    for folder in folders[num_train:]:\n","        num_files = len(os.listdir(os.path.join(directory, folder)))\n","        test_list[folder] = num_files  \n","    \n","    return train_list, test_list\n","\n","train_list, test_list = split_dataset(ROOT, split=0.9)\n","print(\"Length of training list:\", len(train_list))\n","print(\"Length of testing list :\", len(test_list))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#function used to make triplets from the data, returns anchor, positive example and negative example\n","def create_triplets(directory, folder_list, max_files=10):\n","    triplets = []\n","    folders = list(folder_list.keys())\n","    \n","    for folder in folders:\n","        path = os.path.join(directory, folder)\n","        files = list(os.listdir(path))[:max_files]\n","        num_files = len(files)\n","        \n","        for i in range(0,num_files-1):\n","            for j in range(i+1, num_files):\n","                anchor = (folder, f\"{i}.jpg\")\n","                positive = (folder, f\"{j}.jpg\")\n","\n","                neg_folder = folder\n","                while neg_folder == folder:\n","                    neg_folder = random.choice(folders)\n","                neg_file = random.randint(0, folder_list[neg_folder]-1)\n","                negative = (neg_folder, f\"{neg_file}.jpg\")\n","\n","                triplets.append((anchor, positive, negative))\n","            \n","    random.shuffle(triplets)\n","    return triplets"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_triplet = create_triplets(ROOT, train_list)\n","test_triplet  = create_triplets(ROOT, test_list)\n","\n","print(\"Number of training triplets:\", len(train_triplet))\n","print(\"Number of testing triplets :\", len(test_triplet))\n","\n","print(\"\\nExamples of triplets:\")\n","for i in range(5):\n","    print(train_triplet[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#function used get batch for training or testing the network\n","def get_batch(triplet_list, batch_size=256, preprocess=True):\n","    batch_steps = len(triplet_list)//batch_size\n","    \n","    for i in range(batch_steps+1):\n","        anchor   = []\n","        positive = []\n","        negative = []\n","        \n","        j = i*batch_size\n","        while j<(i+1)*batch_size and j<len(triplet_list):\n","            a, p, n = triplet_list[j]\n","            anchor.append(read_image(a))\n","            positive.append(read_image(p))\n","            negative.append(read_image(n))\n","            j+=1\n","            \n","        anchor = np.array(anchor)\n","        positive = np.array(positive)\n","        negative = np.array(negative)\n","        \n","        if preprocess:\n","            anchor = preprocess_input(anchor)\n","            positive = preprocess_input(positive)\n","            negative = preprocess_input(negative)\n","        \n","        yield ([anchor, positive, negative])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num_plots = 6\n","\n","f, axes = plt.subplots(num_plots, 3, figsize=(15, 20))\n","\n","for x in get_batch(train_triplet, batch_size=num_plots, preprocess=False):\n","    a,p,n = x\n","    for i in range(num_plots):\n","        axes[i, 0].imshow(a[i])\n","        axes[i, 1].imshow(p[i])\n","        axes[i, 2].imshow(n[i])\n","        i+=1\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#This function is used to get the ppre-trained encoder architecture from keras \n","#and also we add some more layers on top of it \n","def get_encoder(input_shape):\n","    \"\"\" Returns the image encoding model \"\"\"\n","\n","    pretrained_model = Xception(\n","        input_shape=input_shape,\n","        weights='imagenet',\n","        include_top=False,\n","        pooling='avg',\n","    )\n","    #we freeze the model weights asit is already trained for faster training\n","    for i in range(len(pretrained_model.layers)-27):\n","        pretrained_model.layers[i].trainable = False\n","\n","    encode_model = Sequential([\n","        pretrained_model,\n","        layers.Flatten(),\n","        layers.Dense(512, activation='relu'),\n","        layers.BatchNormalization(),\n","        layers.Dense(256, activation=\"relu\"),\n","        layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n","    ], name=\"Encode_Model\")\n","    return encode_model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#This layer is used to get distance between samples, it is used in loss function\n","class DistanceLayer(layers.Layer):\n","    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","\n","    def call(self, anchor, positive, negative):\n","        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n","        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n","        return (ap_distance, an_distance)\n","    \n","#Here we desgin a siemese network around a encoder\n","def get_siamese_network(input_shape = (128, 128, 3)):\n","    encoder = get_encoder(input_shape)\n","    \n","    # Input Layers for the images\n","    anchor_input   = layers.Input(input_shape, name=\"Anchor_Input\")\n","    positive_input = layers.Input(input_shape, name=\"Positive_Input\")\n","    negative_input = layers.Input(input_shape, name=\"Negative_Input\")\n","    \n","    ## Generate the encodings (feature vectors) for the images\n","    encoded_a = encoder(anchor_input)\n","    encoded_p = encoder(positive_input)\n","    encoded_n = encoder(negative_input)\n","    \n","    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n","    distances = DistanceLayer()(\n","        encoder(anchor_input),\n","        encoder(positive_input),\n","        encoder(negative_input)\n","    )\n","    \n","    # Creating the Model\n","    siamese_network = Model(\n","        inputs  = [anchor_input, positive_input, negative_input],\n","        outputs = distances,\n","        name = \"Siamese_Network\"\n","    )\n","    return siamese_network\n","\n","siamese_network = get_siamese_network()\n","siamese_network.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_model(siamese_network, show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Here we define our siamese model and how it will be trained\n","#We define what will happen during the forward operation and also how loss function is applied\n","class SiameseModel(Model):\n","    # Builds a Siamese model based on a base-model\n","    def __init__(self, siamese_network, margin=1.0):\n","        super(SiameseModel, self).__init__()\n","        \n","        self.margin = margin\n","        self.siamese_network = siamese_network\n","        self.loss_tracker = metrics.Mean(name=\"loss\")\n","\n","    def call(self, inputs):\n","        return self.siamese_network(inputs)\n","\n","    def train_step(self, data):\n","        # GradientTape get the gradients when we compute loss, and uses them to update the weights\n","        with tf.GradientTape() as tape:\n","            loss = self._compute_loss(data)\n","            \n","        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n","        self.optimizer.apply_gradients(zip(gradients, self.siamese_network.trainable_weights))\n","        \n","        self.loss_tracker.update_state(loss)\n","        return {\"loss\": self.loss_tracker.result()}\n","\n","    def test_step(self, data):\n","        loss = self._compute_loss(data)\n","        \n","        self.loss_tracker.update_state(loss)\n","        return {\"loss\": self.loss_tracker.result()}\n","\n","    def _compute_loss(self, data):\n","        # Get the two distances from the network, then compute the triplet loss\n","        ap_distance, an_distance = self.siamese_network(data)\n","        loss = tf.maximum(ap_distance - an_distance + self.margin, 0.0)\n","        return loss\n","\n","    @property\n","    def metrics(self):\n","        # We need to list our metrics so the reset_states() can be called automatically.\n","        return [self.loss_tracker]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["siamese_model = SiameseModel(siamese_network)\n","\n","optimizer = Adam(learning_rate=1e-3, epsilon=1e-01)\n","siamese_model.compile(optimizer=optimizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#This function is used while training to get the test scores on test set\n","def test_on_triplets(batch_size = 256):\n","    pos_scores, neg_scores = [], []\n","\n","    for data in get_batch(test_triplet, batch_size=batch_size):\n","        prediction = siamese_model.predict(data)\n","        pos_scores += list(prediction[0])\n","        neg_scores += list(prediction[1])\n","    \n","    accuracy = np.sum(np.array(pos_scores) < np.array(neg_scores)) / len(pos_scores)\n","    ap_mean = np.mean(pos_scores)\n","    an_mean = np.mean(neg_scores)\n","    ap_stds = np.std(pos_scores)\n","    an_stds = np.std(neg_scores)\n","    \n","    print(f\"Accuracy on test = {accuracy:.5f}\")\n","    return (accuracy, ap_mean, an_mean, ap_stds, an_stds)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#training the model\n","save_all = False\n","epochs = 30\n","batch_size = 128\n","\n","max_acc = 0\n","train_loss = []\n","test_metrics = []\n","\n","for epoch in range(1, epochs+1):\n","    t = time.time()\n","    \n","    # Training the model on train data\n","    epoch_loss = []\n","    for data in get_batch(train_triplet, batch_size=batch_size):\n","        loss = siamese_model.train_on_batch(data)\n","        epoch_loss.append(loss)\n","    epoch_loss = sum(epoch_loss)/len(epoch_loss)\n","    train_loss.append(epoch_loss)\n","\n","    print(f\"\\nEPOCH: {epoch} \\t (Epoch done in {int(time.time()-t)} sec)\")\n","    print(f\"Loss on train    = {epoch_loss:.5f}\")\n","    \n","    # Testing the model on test data\n","    metric = test_on_triplets(batch_size=batch_size)\n","    test_metrics.append(metric)\n","    accuracy = metric[0]\n","    \n","    # Saving the model weights\n","    if save_all or accuracy>=max_acc:\n","        siamese_model.save(\"siamese_model_final_wof/\",save_format='tf') \n","        max_acc = accuracy\n","\n","# Saving the model after all epochs run\n","siamese_model.save(\"siamese_model_final_wof/\",save_format='tf') "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import shutil\n","# shutil.make_archive(\"/kaggle/working/wwfinal_siamese_model_final_wof_saved\", 'zip', \"/kaggle/working/siamese_model_final_wof\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Extracting encoder which will be used to generate embeddings or features\n","def extract_encoder(model):\n","    encoder = get_encoder((128, 128, 3))\n","    i=0\n","    for e_layer in model.layers[0].layers[3].layers:\n","        layer_weight = e_layer.get_weights()\n","        encoder.layers[i].set_weights(layer_weight)\n","        i+=1\n","    return encoder\n","\n","encoder = extract_encoder(siamese_model)\n","encoder.save(\"encoder_ourfaces.h5\")\n","encoder.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# encoder=tf.keras.models.load_model('/kaggle/input/siamese-encoder/encoder_siamese.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Functions to get FAR and FRR values (coded by student)\n","def get_FAR(face_list1, face_list2, threshold=1.7):\n","    # Getting the encodings for the passed faces\n","    tensor1 = encoder.predict(face_list1)\n","    tensor2 = encoder.predict(face_list2)\n","    distance = np.sum(np.square(tensor1-tensor2), axis=-1)\n","    FAR = np.where(distance<=threshold, 1, 0)\n","    return FAR\n","\n","def get_FRR(face_list1, face_list2, threshold=1.3):\n","    # Getting the encodings for the passed faces\n","    tensor1 = encoder.predict(face_list1)\n","    tensor2 = encoder.predict(face_list2)\n","    distance = np.sum(np.square(tensor1-tensor2), axis=-1)\n","    FRR = np.where(distance>threshold, 1, 0)\n","    return FRR"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Get FAR and FRR values for a certain threshold value intervals\n","pos_list = np.array([])\n","neg_list = np.array([])\n","FRR = []\n","FAR= []\n","thresold_vals=list(np.arange(1, 1.9+0.2, 0.2))\n","\n","\n","for data in get_batch(test_triplet, batch_size=256):\n","        a, p, n = data\n","        for th in thresold_vals:\n","            pos_list = np.append(pos_list, get_FRR(a, p,threshold=th))\n","            neg_list = np.append(neg_list, get_FAR(a, n,threshold=th))\n","            FRR_rate=sum(pos_list)/len(pos_list)\n","            FAR_rate=sum(neg_list)/len(neg_list)\n","            FRR.append(FRR_rate)\n","            FAR.append(FAR_rate)\n","        break\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#plot the FAR and FRR plots\n","import matplotlib.pyplot as plt\n","\n","# Your lists for False Rejection Rate (FRR) and False Acceptance Rate (FAR)\n","\n","# Your thresholds\n","thresholds = thresold_vals\n","\n","# Create the plot\n","plt.plot(thresholds, FRR, label='FRR')\n","plt.plot(thresholds, FAR, label='FAR')\n","\n","# Add labels and legend\n","plt.xlabel('Threshold')\n","plt.ylabel('Rate')\n","plt.legend()\n","plt.title('FRR vs FAR on test subset')\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Get embeddings for face to make face encoding Database"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_folder_names(path):\n","    return [os.path.join(path, d) for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n","\n","def get_images(n):\n","    folder_names = get_folder_names('/kaggle/input/face-recog-test/Biometric_data/')\n","    images=[]\n","    for folder in folder_names:\n","        images_in_folder = os.listdir(folder)\n","        chosen_images = random.sample(images_in_folder, n)\n","        images += [os.path.join(folder, image) for image in chosen_images]\n","\n","    return images\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["encodings=[]\n","names=[]\n","for i in get_images(2):\n","    ttimages=cv2.imread(i)\n","    ttimages = cv2.cvtColor(ttimages, cv2.COLOR_BGR2RGB)\n","    ttimages=cv2.resize(ttimages, (128,128), interpolation = cv2.INTER_AREA)\n","    ttimages=np.expand_dims(ttimages, axis=0)\n","    ttimages=preprocess_input(ttimages)\n","    enc1=encoder(ttimages)\n","    encodings.append(enc1[0])\n","    names.append(os.path.basename(os.path.dirname(i)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# distance = np.sum(np.square(encodings[5]-encodings[4]), axis=-1)\n","# distance"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["encodings=np.stack(encodings, axis=0)\n","names=np.array(names)\n","np.savez('names_en.npz', names=names)\n","np.savez('encodings_en.npz', names=encodings)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# loaded_name = np.load('/kaggle/working/names.npz')\n","# names_array = loaded_name['names']\n","\n","# loaded_enc = np.load('/kaggle/working/encodings.npz')\n","# encoding = loaded_enc['names']\n","# print(encoding)"]},{"cell_type":"markdown","metadata":{},"source":["## Convert model to ONNX format for faster inference"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install onnxruntime\n","!pip install -U tf2onnx"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# (coded by student)\n","import tf2onnx\n","import onnxruntime as rt\n","\n","spec = (tf.TensorSpec((None, 128, 128, 3), tf.float32, name=\"input\"),)\n","output_path = \"face-recog_enc\" + \".onnx\"\n","\n","model_proto, _ = tf2onnx.convert.from_keras(encoder, input_signature=spec, opset=13, output_path=output_path)\n","output_names = [n.name for n in model_proto.graph.output]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["providers = ['CPUExecutionProvider']\n","m = rt.InferenceSession('/kaggle/working/face-recog.onnx', providers=providers)\n","onnx_pred = m.run(output_names, {\"input\": a})\n","\n","# print('ONNX Predicted:',onnx_pred)\n","\n","# make sure ONNX and keras have the same results\n","# np.testing.assert_allclose(pred, onnx_pred[0], rtol=1e-5)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#preprocess function should be used mandatory for getting enccoding at inference\n","def c_preprocess_input(x):\n","    x = x.astype('float32')\n","    x /= 255.\n","    x -= 0.5\n","    x *= 2.\n","    return x\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
