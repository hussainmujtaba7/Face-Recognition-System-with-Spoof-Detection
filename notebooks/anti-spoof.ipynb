{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"* Refrences used for utlity functions :https://www.kaggle.com/code/duchuy/face-anti-spoofing\n> Note: The evaluation and modelling part done by students\n> ","metadata":{}},{"cell_type":"code","source":"# Import the  library from Python \nimport numpy as np \nimport pandas as pd \nimport os\nimport cv2\nimport matplotlib.pyplot as plt\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Utility code to extract faces from the images using the bounding box text files\ndef get_ratio_bbox_and_image(full_img_path, bound_box_path):\n    img = cv2.imread(full_img_path)\n    real_h, real_w, _ = img.shape\n    area_image = real_h * real_w\n    x1, y1, w1, h1 = get_area_bbox_indices(bound_box_path, real_w, real_h)\n    area_bbox = w1*h1\n    return area_bbox / area_image\n\n\ndef standard_width_height_scaling(real_w, real_h, bbox0, bbox1, bbox2, bbox3):\n    x1 = int(int(bbox0)*(float(real_w) / 224)) # bbox[0]\n    y1 = int(int(bbox1)*(float(real_h) / 224)) # bbox[1]\n    w1 = int(int(bbox2)*(float(real_w) / 224)) # bbox[2]\n    h1 = int(int(bbox3)*(float(real_h) / 224)) # bbox[3]\n    return x1, y1, w1, h1\n\n\ndef get_area_bbox_indices(bound_box_path, real_w, real_h):\n    bound_box_read = open(bound_box_path, \"r\")\n    bound_box_indices = list()\n    for i in bound_box_read:\n        bound_box_indices.append(i)\n    bbox = bound_box_indices[0].split()\n    x1, y1, w1, h1 = standard_width_height_scaling(real_w, real_h, \n                                                   bbox[0], bbox[1], bbox[2], bbox[3])\n    return x1, y1, w1, h1\n\ndef get_padding_bbox_indices(x1, y1, w1, h1, real_w, real_h, ratio_bbox_and_image):\n    x1_padding = x1 - int((w1) * (1+ratio_bbox_and_image))\n    y1_padding = y1 - int((h1) * (1+ratio_bbox_and_image))\n    w1_padding = w1 + int((w1) * (1+ratio_bbox_and_image))\n    h1_padding = h1 + int((h1) * (1+ratio_bbox_and_image))\n    if x1_padding < 0: \n        x1_padding = 0\n    if y1_padding < 0:\n        y1_padding = 0\n    if w1_padding > real_w:\n        w1_padding = real_w\n    if h1_padding > real_h:\n        h1_padding = real_h\n    return x1_padding, y1_padding, w1_padding, h1_padding\n    \ndef read_crop_img_with_bbox(full_img_path, bound_box_path):\n    img = cv2.imread(full_img_path)\n    real_w = img.shape[1]\n    real_h = img.shape[0]\n    x1, y1, w1, h1 = get_area_bbox_indices(bound_box_path, real_w, real_h)\n    return x1, y1, w1, h1, img, real_w, real_h","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# code to extract the faces and label images as spoof or not spoof\noriginal_cropped_storage = []\npadding_cropped_storage = []\nimg_names = []\noriginal_cropped_labels = []\npadding_cropped_labels = []\n\ncount_live = 0\ncount_spoof = 0\ndim = (128, 128)\n#add limit to the amount of data used for training\ncount_limit_live = 10000\ncount_limit_spoof = 10000\n\nrootdir_train = '/kaggle/input/celeba-spoof-for-face-antispoofing/CelebA_Spoof_/CelebA_Spoof/Data/train'\nfor file in os.listdir(rootdir_train):\n    d = os.path.join(rootdir_train, file)\n    if os.path.isdir(d):\n        for e in os.listdir(d):\n            imgs_path = d + '/' + e + '/'\n            for img_path in os.listdir(imgs_path):\n                if (img_path.endswith(\".jpg\")):\n                    full_img_path = imgs_path + img_path\n                    bound_box_path = full_img_path[0:-4] + '_BB.txt'\n                    x1, y1, w1, h1, img, real_w, real_h = read_crop_img_with_bbox(full_img_path, bound_box_path)\n                    ratio_bbox_and_image = get_ratio_bbox_and_image(full_img_path, bound_box_path)\n                    x1_padding, y1_padding, w1_padding, h1_padding = get_padding_bbox_indices(x1, y1, w1, h1, \n                                                                                              real_w, real_h,\n                                                                                              ratio_bbox_and_image)\n                    padding_img = img[y1_padding:y1+h1_padding, x1_padding:x1+w1_padding]\n                    try:\n                        if (e == 'live' and count_live >= count_limit_live) or (e == 'spoof' and count_spoof >= count_limit_spoof):\n                            continue\n                        resized_padding_img = cv2.resize(padding_img, dim, interpolation = cv2.INTER_AREA)\n                        padding_cropped_storage.append(resized_padding_img)\n                        if e == 'live':\n                            count_live = count_live + 1\n                            padding_cropped_labels.append(0)\n                        elif e == 'spoof':\n                            count_spoof = count_spoof + 1\n                            padding_cropped_labels.append(1)\n                    except:\n                        continue\n                    img_names.append(img_path)\n                    if (count_live == count_limit_live and e == 'live') or (count_spoof == count_limit_spoof and e == 'spoof'):\n                        break\n            if count_live >= count_limit_live and count_spoof >= count_limit_spoof:\n                break\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the numpy to NUMPYZ \nX = np.asarray(padding_cropped_storage)\ny = np.asarray(padding_cropped_labels)\nnp.savez('anti_spoofing_data.npz', X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anti_spoofing_data = np.load('/kaggle/input/celeb-data-saved/anti_spoofing_data.npz')\nX, y = anti_spoofing_data['arr_0'], anti_spoofing_data['arr_1']\ntemp = set(y)\ncheck_live_label = 0\ncheck_spoof_label = 0\nfor i in y: \n    if i == 0:\n        check_live_label += 1\n    elif i == 1:\n        check_spoof_label += 1\nprint(f\"There are 2 classes including number of live is {check_live_label} and number of spoof is {check_spoof_label}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n#     plt.imshow(original_cropped_storage[i])\n    plt.imshow(X[i])\n#     plt.xlabel(class_names[train_labels[i][0]])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport numpy as np\n\nprint(X.shape)\nprint(y.shape)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\nX_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)\nprint(f'Training dataset size of X_train: {len(X_train)}')\nprint(f'Testing dataset size of X_test: {len(X_test)}')\nprint(f'Validation dataset size of X_valid: {len(X_valid)}')\nprint(f'Testing dataset size of y_train: {len(y_train)}')\nprint(f'Testing dataset size of y_test: {len(y_test)}')\nprint(f'Testing dataset size of y_valid: {len(y_valid)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow.keras import datasets, layers, models\nimport matplotlib.pyplot as plt\n\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(1,activation='sigmoid'))\n\nmodel.summary()\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=['accuracy'])\n# X_train, X_test, y_train, y_test\nhistory = model.fit(X_train, y_train, epochs=10, \n                    validation_data=(X_valid, y_valid))\n# model.save(\"./my_model.h5\") ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\n\ntest_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions=model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#code to get FAR and FRR values\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nFAR=[]\nFRR=[]\nthresold_vals=[0.1, 0.2, 0.3,0.4, 0.5, 0.6,0.7,0.8, 0.9]\ny_true = y_test\nfor i in thresold_vals:\n    y_pred = [0 if p < i else 1 for p in predictions]\n    # Calculate the confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Extract the values of the confusion matrix\n    TN, FP, FN, TP = cm.ravel()\n\n    # Calculate FAR and FRR\n    FAR.append (FP / (FP + TN))\n    FRR.append(FN / (FN + TP))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Your lists for False Rejection Rate (FRR) and False Acceptance Rate (FAR)\n\n# Your thresholds\nthresholds = thresold_vals\n\n# Create the plot\nplt.plot(thresholds, FRR, label='FRR')\nplt.plot(thresholds, FAR, label='FAR')\n\n# Add labels and legend\nplt.xlabel('Threshold')\nplt.ylabel('Rate')\nplt.legend()\nplt.title('FRR vs FAR on test subset for anti-spoof classifier')\n\n# Show the plot\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install onnxruntime\n!pip install -U tf2onnx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tf2onnx\nimport onnxruntime as rt\n\nspec = (tf.TensorSpec((None, 128, 128, 3), tf.uint8, name=\"input\"),)\noutput_path = \"anti-spoof\" + \".onnx\"\n\nmodel_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13, output_path=output_path)\noutput_names = [n.name for n in model_proto.graph.output]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"providers = ['CPUExecutionProvider']\nm = rt.InferenceSession(output_path, providers=providers)\nonnx_pred = m.run(['dense_13'], {\"input\": X_valid})\n\nprint('ONNX Predicted:',onnx_pred)\n\n# make sure ONNX and keras have the same results\nnp.testing.assert_allclose(pred, onnx_pred[0], rtol=1e-5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.make_archive(\"/kaggle/working/model1\", 'zip', \"/kaggle/working/model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}