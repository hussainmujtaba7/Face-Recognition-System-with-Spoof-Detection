{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# Import the  library from Python \n","import numpy as np \n","import pandas as pd \n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Utility code to extract faces from the images using the bounding box text files\n","def get_ratio_bbox_and_image(full_img_path, bound_box_path):\n","    img = cv2.imread(full_img_path)\n","    real_h, real_w, _ = img.shape\n","    area_image = real_h * real_w\n","    x1, y1, w1, h1 = get_area_bbox_indices(bound_box_path, real_w, real_h)\n","    area_bbox = w1*h1\n","    return area_bbox / area_image\n","\n","\n","def standard_width_height_scaling(real_w, real_h, bbox0, bbox1, bbox2, bbox3):\n","    x1 = int(int(bbox0)*(float(real_w) / 224)) # bbox[0]\n","    y1 = int(int(bbox1)*(float(real_h) / 224)) # bbox[1]\n","    w1 = int(int(bbox2)*(float(real_w) / 224)) # bbox[2]\n","    h1 = int(int(bbox3)*(float(real_h) / 224)) # bbox[3]\n","    return x1, y1, w1, h1\n","\n","\n","def get_area_bbox_indices(bound_box_path, real_w, real_h):\n","    bound_box_read = open(bound_box_path, \"r\")\n","    bound_box_indices = list()\n","    for i in bound_box_read:\n","        bound_box_indices.append(i)\n","    bbox = bound_box_indices[0].split()\n","    x1, y1, w1, h1 = standard_width_height_scaling(real_w, real_h, \n","                                                   bbox[0], bbox[1], bbox[2], bbox[3])\n","    return x1, y1, w1, h1\n","\n","def get_padding_bbox_indices(x1, y1, w1, h1, real_w, real_h, ratio_bbox_and_image):\n","    x1_padding = x1 - int((w1) * (1+ratio_bbox_and_image))\n","    y1_padding = y1 - int((h1) * (1+ratio_bbox_and_image))\n","    w1_padding = w1 + int((w1) * (1+ratio_bbox_and_image))\n","    h1_padding = h1 + int((h1) * (1+ratio_bbox_and_image))\n","    if x1_padding < 0: \n","        x1_padding = 0\n","    if y1_padding < 0:\n","        y1_padding = 0\n","    if w1_padding > real_w:\n","        w1_padding = real_w\n","    if h1_padding > real_h:\n","        h1_padding = real_h\n","    return x1_padding, y1_padding, w1_padding, h1_padding\n","    \n","def read_crop_img_with_bbox(full_img_path, bound_box_path):\n","    img = cv2.imread(full_img_path)\n","    real_w = img.shape[1]\n","    real_h = img.shape[0]\n","    x1, y1, w1, h1 = get_area_bbox_indices(bound_box_path, real_w, real_h)\n","    return x1, y1, w1, h1, img, real_w, real_h"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# code to extract the faces and label images as spoof or not spoof\n","original_cropped_storage = []\n","padding_cropped_storage = []\n","img_names = []\n","original_cropped_labels = []\n","padding_cropped_labels = []\n","\n","count_live = 0\n","count_spoof = 0\n","dim = (128, 128)\n","#add limit to the amount of data used for training\n","count_limit_live = 10000\n","count_limit_spoof = 10000\n","\n","rootdir_train = '/kaggle/input/celeba-spoof-for-face-antispoofing/CelebA_Spoof_/CelebA_Spoof/Data/train'\n","for file in os.listdir(rootdir_train):\n","    d = os.path.join(rootdir_train, file)\n","    if os.path.isdir(d):\n","        for e in os.listdir(d):\n","            imgs_path = d + '/' + e + '/'\n","            for img_path in os.listdir(imgs_path):\n","                if (img_path.endswith(\".jpg\")):\n","                    full_img_path = imgs_path + img_path\n","                    bound_box_path = full_img_path[0:-4] + '_BB.txt'\n","                    x1, y1, w1, h1, img, real_w, real_h = read_crop_img_with_bbox(full_img_path, bound_box_path)\n","                    ratio_bbox_and_image = get_ratio_bbox_and_image(full_img_path, bound_box_path)\n","                    x1_padding, y1_padding, w1_padding, h1_padding = get_padding_bbox_indices(x1, y1, w1, h1, \n","                                                                                              real_w, real_h,\n","                                                                                              ratio_bbox_and_image)\n","                    padding_img = img[y1_padding:y1+h1_padding, x1_padding:x1+w1_padding]\n","                    try:\n","                        if (e == 'live' and count_live >= count_limit_live) or (e == 'spoof' and count_spoof >= count_limit_spoof):\n","                            continue\n","                        resized_padding_img = cv2.resize(padding_img, dim, interpolation = cv2.INTER_AREA)\n","                        padding_cropped_storage.append(resized_padding_img)\n","                        if e == 'live':\n","                            count_live = count_live + 1\n","                            padding_cropped_labels.append(0)\n","                        elif e == 'spoof':\n","                            count_spoof = count_spoof + 1\n","                            padding_cropped_labels.append(1)\n","                    except:\n","                        continue\n","                    img_names.append(img_path)\n","                    if (count_live == count_limit_live and e == 'live') or (count_spoof == count_limit_spoof and e == 'spoof'):\n","                        break\n","            if count_live >= count_limit_live and count_spoof >= count_limit_spoof:\n","                break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Save the numpy to NUMPYZ \n","X = np.asarray(padding_cropped_storage)\n","y = np.asarray(padding_cropped_labels)\n","np.savez('anti_spoofing_data.npz', X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["anti_spoofing_data = np.load('/kaggle/input/celeb-data-saved/anti_spoofing_data.npz')\n","X, y = anti_spoofing_data['arr_0'], anti_spoofing_data['arr_1']\n","temp = set(y)\n","check_live_label = 0\n","check_spoof_label = 0\n","for i in y: \n","    if i == 0:\n","        check_live_label += 1\n","    elif i == 1:\n","        check_spoof_label += 1\n","print(f\"There are 2 classes including number of live is {check_live_label} and number of spoof is {check_spoof_label}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","for i in range(25):\n","    plt.subplot(5,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","#     plt.imshow(original_cropped_storage[i])\n","    plt.imshow(X[i])\n","#     plt.xlabel(class_names[train_labels[i][0]])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","print(X.shape)\n","print(y.shape)\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)\n","print(f'Training dataset size of X_train: {len(X_train)}')\n","print(f'Testing dataset size of X_test: {len(X_test)}')\n","print(f'Validation dataset size of X_valid: {len(X_valid)}')\n","print(f'Testing dataset size of y_train: {len(y_train)}')\n","print(f'Testing dataset size of y_test: {len(y_test)}')\n","print(f'Testing dataset size of y_valid: {len(y_valid)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","\n","\n","model = models.Sequential()\n","model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(1,activation='sigmoid'))\n","\n","model.summary()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.BinaryCrossentropy(),\n","              metrics=['accuracy'])\n","# X_train, X_test, y_train, y_test\n","history = model.fit(X_train, y_train, epochs=10, \n","                    validation_data=(X_valid, y_valid))\n","# model.save(\"./my_model.h5\") "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.plot(history.history['accuracy'], label='accuracy')\n","plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.ylim([0.5, 1])\n","plt.legend(loc='lower right')\n","\n","test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["predictions=model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#code to get FAR and FRR values\n","from sklearn.metrics import confusion_matrix\n","import numpy as np\n","FAR=[]\n","FRR=[]\n","thresold_vals=[0.1, 0.2, 0.3,0.4, 0.5, 0.6,0.7,0.8, 0.9]\n","y_true = y_test\n","for i in thresold_vals:\n","    y_pred = [0 if p < i else 1 for p in predictions]\n","    # Calculate the confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    # Extract the values of the confusion matrix\n","    TN, FP, FN, TP = cm.ravel()\n","\n","    # Calculate FAR and FRR\n","    FAR.append (FP / (FP + TN))\n","    FRR.append(FN / (FN + TP))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Your lists for False Rejection Rate (FRR) and False Acceptance Rate (FAR)\n","\n","# Your thresholds\n","thresholds = thresold_vals\n","\n","# Create the plot\n","plt.plot(thresholds, FRR, label='FRR')\n","plt.plot(thresholds, FAR, label='FAR')\n","\n","# Add labels and legend\n","plt.xlabel('Threshold')\n","plt.ylabel('Rate')\n","plt.legend()\n","plt.title('FRR vs FAR on test subset for anti-spoof classifier')\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install onnxruntime\n","!pip install -U tf2onnx"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import tf2onnx\n","import onnxruntime as rt\n","\n","spec = (tf.TensorSpec((None, 128, 128, 3), tf.uint8, name=\"input\"),)\n","output_path = \"anti-spoof\" + \".onnx\"\n","\n","model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13, output_path=output_path)\n","output_names = [n.name for n in model_proto.graph.output]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["providers = ['CPUExecutionProvider']\n","m = rt.InferenceSession(output_path, providers=providers)\n","onnx_pred = m.run(['dense_13'], {\"input\": X_valid})\n","\n","print('ONNX Predicted:',onnx_pred)\n","\n","# make sure ONNX and keras have the same results\n","np.testing.assert_allclose(pred, onnx_pred[0], rtol=1e-5)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import shutil\n","# shutil.make_archive(\"/kaggle/working/model1\", 'zip', \"/kaggle/working/model\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
